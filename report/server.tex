SimpleChubby server keeps two types of states. First, the
leader server maintains in-memory data structures, which will be lost
after a leader change. Second, the data need to be persistent are replicated
among leader and follower servers using the Viewstamp protocol.


\subsubsection{In-Memory Data Structures}

SimpleChubby uses a file handler mechanism. The file handler can be very
handy when an application is sensitive to obsolete files. Since the server
rejects any requests with invalid file handlers (i.e. meta-data in the file
handler does not match with server's record), the client detects that the node has
been deleted or re-created after receiving a failure of an operation with
the previously opened file handler. The server also rejects any fake file
handlers by checking the digital signitures in them signed during successful
\texttt{fileOpen()} operations.

However, maintaining the information of file handlers persistent on the servers can
be challenging, since queries for file handlers are frequent and the lengths
of the opened file handler lists dynamically change. Therefore, we choose
to keep this information in memory instead of in persistent store, in order
to reduce the overhead of the Viewstamp protocol. In the normal case, a file
handler is created in \texttt{fileOpen()} and destoyed in either
\texttt{fileClose()} or \texttt{fileDelete()}.
All requests from clients except \texttt{fileOpen()} take file handlers as
arguments,
and the server returns failures if the file handlers do not match with
server's records.

Another part of in-memory data structures is the queues of outstanding lock
acquire requests for different nodes. Upon any \texttt{acquire()} request, the
leader server adds the client's session information into the queue and
blocks the RPC if the lock is held by another client.
In a \texttt{release()} request, the server pops out a waiting session
(if there is any) on the same lock, modifies the lock owner, and unblocks and
returns the correspongding \texttt{acquire()} request.

We also store clients' request records for events in the leader server's memory.
For each type of event, there are separate lists for different nodes.
The client's session information will be added to the lists during
\texttt{fileOpen()}
request if event registration flags are set. Once a event happens,
the server iterates through the list, and sends the event to the client if the
session is still alive.

\subsubsection{Persistent Data Store}

The main part of persistent data is the Chubby file system. Each node has
a full path name as the key, a string of content, the meta data defined
in the SimpleChubby API, and a lock owner field. A normal node open returns
the instance number of the node in order to form a file handler, while
a node creation triggered by \texttt{fileOpen()} takes a unique ascending
instance number from server and creates a node in the file system. All other
operations on the filesystem (including the lock operations that change lock owners)
take both the name and the instance number of the node as arguments, and will
abort if the node does not exist or the instance number doesn't match the
meta data.

Another persistent data is the value of the next instance number. This global
value is increased by one every time a new node is created, and is passed
to the node creation operation as discussed above. It works as a timestamp,
which helps the server detect and reject the client requests with obsolete
file handlers.
